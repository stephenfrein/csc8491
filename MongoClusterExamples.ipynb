{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOi6xtbqjrg2FSA+J0g3Khl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenfrein/csc8491/blob/main/MongoClusterExamples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HvVnN1_Ad3Hq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "045e0ad0-bf3f-4a1e-eb46-72c76c920bbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.1/669.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.6.1 pymongo-4.7.3\n"
          ]
        }
      ],
      "source": [
        "# install a Python library that interacts with MongoDB\n",
        "!pip install pymongo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up your credentials - same as your Oracle credentials\n",
        "username = ''\n",
        "password = ''"
      ],
      "metadata": {
        "id": "mL1rA7wIelJ3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test your connection - if it fails, check username/password\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "uri = \"mongodb+srv://\"+username+\":\"+password+\"@cluster0.yrg2exm.mongodb.net\"\n",
        "# create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "# send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "dF1xxX37ehE9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1af5041-33d5-41cb-d3e5-85bb55d63740"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinged your deployment. You successfully connected to MongoDB!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OBSERVE THE PROPAGATION DELAY IN A CLUSTER\n",
        "\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import threading\n",
        "import time\n",
        "from pymongo import ReadPreference\n",
        "\n",
        "# transactions in a CSV file in an AWS S3 bucket\n",
        "transactions_url = 'https://csc8491.s3.amazonaws.com/mongo_transactions_24.csv'\n",
        "# name of collection\n",
        "trans_collection = 'transactions'\n",
        "\n",
        "# you have a database that matches your username\n",
        "db = client[username]\n",
        "collection = db[trans_collection]\n",
        "\n",
        "# get rid of collection if it already exists\n",
        "try:\n",
        "  collection.drop()\n",
        "except e:\n",
        "  print(e)\n",
        "\n",
        "# function to load our collection from the S3 file - we'll run this in a thread\n",
        "def load_collection(collection, filename):\n",
        "    data = pd.read_csv(filename, header=0)\n",
        "    collection.insert_many(data.to_dict('records'))\n",
        "\n",
        "# function to get the count in a collection - we'll read this for both the primary and a secondary\n",
        "def get_count(collection, type):\n",
        "  # we read it 20 times in a row to compare how loading progresses for the primary or the secondary\n",
        "  for i in range(1,21):\n",
        "    print('\\n' + type + ' ' + str(i) + ': ' + str(collection.count_documents({})) + ' ' + str(datetime.datetime.now()))\n",
        "\n",
        "# reference to the collection for loading\n",
        "trans_load = db.get_collection(trans_collection)\n",
        "# reference to the collection as it exists on the primary node - we will use for reading\n",
        "trans_primary = db.get_collection(trans_collection, read_preference=ReadPreference.PRIMARY)\n",
        "# reference to the collection as it exists on a secondary node - we will use for reading\n",
        "trans_secondary = db.get_collection(trans_collection, read_preference=ReadPreference.SECONDARY)\n",
        "\n",
        "# thread for loading data\n",
        "t_load_data = threading.Thread(target=load_collection, args=(trans_load,transactions_url,))\n",
        "# thread for reading from primary\n",
        "t_count_primary = threading.Thread(target=get_count, args=(trans_primary,'Primary',))\n",
        "# thread for reading froms secondary\n",
        "t_count_secondary = threading.Thread(target=get_count, args=(trans_secondary,'Secondary',))\n",
        "\n",
        "# start the clock\n",
        "start = time.time()\n",
        "\n",
        "# starting load thread\n",
        "t_load_data.start()\n",
        "# give load time to get moving\n",
        "time.sleep(15)\n",
        "# start reading from primary\n",
        "t_count_primary.start()\n",
        "# start reading from secondary\n",
        "t_count_secondary.start()\n",
        "\n",
        "# wait until threads are completely executed\n",
        "t_load_data.join()\n",
        "t_count_primary.join()\n",
        "t_count_secondary.join()\n",
        "\n",
        "# stop the clock\n",
        "end = time.time()\n",
        "print(\"Run took: \" + str(end - start) + ' seconds')\n",
        "\n",
        "# what are our final numbers once load is complete?\n",
        "print('Final Primary: ' + str(trans_primary.count_documents({})))\n",
        "print('Final Secondary: ' + str(trans_secondary.count_documents({})))\n"
      ],
      "metadata": {
        "id": "nNgVKZVTGxlE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6eb4bfb3-dfe9-4a71-e372-6c5bb0801bdb"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Secondary 1: 100000 2024-06-17 18:08:56.244671\n",
            "\n",
            "Secondary 2: 100000 2024-06-17 18:08:56.398813\n",
            "\n",
            "Secondary 3: 100000 2024-06-17 18:08:56.511181\n",
            "\n",
            "Secondary 4: 100000 2024-06-17 18:08:56.644490\n",
            "\n",
            "Secondary 5: 100704 2024-06-17 18:08:57.083849\n",
            "\n",
            "Secondary 6: 101664 2024-06-17 18:08:57.243691\n",
            "\n",
            "Secondary 7: 102688 2024-06-17 18:08:57.399910\n",
            "\n",
            "Secondary 8: 103904 2024-06-17 18:08:57.565235\n",
            "\n",
            "Secondary 9: 104672 2024-06-17 18:08:57.714464\n",
            "\n",
            "Secondary 10: 105568 2024-06-17 18:08:57.847007\n",
            "\n",
            "Secondary 11: 105888 2024-06-17 18:08:57.977706\n",
            "\n",
            "Secondary 12: 108576 2024-06-17 18:08:58.139752\n",
            "\n",
            "Secondary 13: 109216 2024-06-17 18:08:58.283550\n",
            "\n",
            "Secondary 14: 112096 2024-06-17 18:08:58.486534\n",
            "\n",
            "Secondary 15: 113312 2024-06-17 18:08:58.666565\n",
            "\n",
            "Secondary 16: 115424 2024-06-17 18:08:58.823481\n",
            "\n",
            "Secondary 17: 116640 2024-06-17 18:08:59.009321\n",
            "\n",
            "Secondary 18: 118112 2024-06-17 18:08:59.156555\n",
            "\n",
            "Secondary 19: 119712 2024-06-17 18:08:59.335712\n",
            "\n",
            "Secondary 20: 120480 2024-06-17 18:08:59.457260\n",
            "\n",
            "Primary 1: 176096 2024-06-17 18:09:06.948388\n",
            "\n",
            "Primary 2: 200000 2024-06-17 18:09:12.977743\n",
            "\n",
            "Primary 3: 202688 2024-06-17 18:09:19.553955\n",
            "\n",
            "Primary 4: 221824 2024-06-17 18:09:24.547224\n",
            "\n",
            "Primary 5: 234432 2024-06-17 18:09:28.033123\n",
            "\n",
            "Primary 6: 246848 2024-06-17 18:09:31.171742\n",
            "\n",
            "Primary 7: 248768 2024-06-17 18:09:34.417045\n",
            "\n",
            "Primary 8: 249152 2024-06-17 18:09:36.406974\n",
            "\n",
            "Primary 9: 256512 2024-06-17 18:09:38.688266\n",
            "\n",
            "Primary 10: 270784 2024-06-17 18:09:42.152944\n",
            "\n",
            "Primary 11: 284352 2024-06-17 18:09:45.069850\n",
            "\n",
            "Primary 12: 296384 2024-06-17 18:09:47.827577\n",
            "\n",
            "Primary 13: 300000 2024-06-17 18:09:49.725146\n",
            "\n",
            "Primary 14: 300000 2024-06-17 18:09:51.539665\n",
            "\n",
            "Primary 15: 313760 2024-06-17 18:09:55.159822\n",
            "\n",
            "Primary 16: 332768 2024-06-17 18:09:59.309759\n",
            "\n",
            "Primary 17: 349984 2024-06-17 18:10:03.033690\n",
            "\n",
            "Primary 18: 366048 2024-06-17 18:10:06.984605\n",
            "\n",
            "Primary 19: 385568 2024-06-17 18:10:11.581969\n",
            "\n",
            "Primary 20: 400000 2024-06-17 18:10:15.458364\n",
            "Run took: 101.0604476928711 seconds\n",
            "Final Primary: 404641\n",
            "Final Secondary: 404641\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OBSERVE THE PERFORMANCE IMPACTS OF DIFFERENT WRITE CONCERNS\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "from pymongo import WriteConcern\n",
        "\n",
        "# transactions in a CSV file in an AWS S3 bucket\n",
        "transactions_url = 'https://csc8491.s3.amazonaws.com/mongo_transactions_24.csv'\n",
        "# name of collection\n",
        "trans_collection = 'transactions'\n",
        "\n",
        "# you have a database that matches your username\n",
        "db = client[username]\n",
        "collection = db[trans_collection]\n",
        "\n",
        "# get rid of collection if it already exists\n",
        "try:\n",
        "  collection.drop()\n",
        "except e:\n",
        "  print(e)\n",
        "\n",
        "# function to load our collection from the S3 file\n",
        "# do it in a loop to better see performance impacts\n",
        "def load_collection(collection, filename):\n",
        "    df = pd.read_csv(filename, header=0)\n",
        "    df = df.iloc[:1000] # grab first thousand records\n",
        "    for index, row in df.iterrows():\n",
        "      collection.insert_one(row.to_dict())\n",
        "\n",
        "# reference to the collection for loading\n",
        "# manipulate write concern to affect speed\n",
        "\n",
        "# default gives majority - 2 nodes in this 3-node cluster (primary + 1 secondary)\n",
        "trans_load = db.get_collection(trans_collection)\n",
        "# setting write concern to 0 means no write acknowledgement needed - super fast\n",
        "# trans_load = db.get_collection(trans_collection, write_concern=WriteConcern(w=0))\n",
        "# setting write concern to 1 means just the primary has to acknowledge\n",
        "# trans_load = db.get_collection(trans_collection, write_concern=WriteConcern(w=1))\n",
        "\n",
        "# start the clock\n",
        "start = time.time()\n",
        "# load the data\n",
        "load_collection(trans_load, transactions_url)\n",
        "# stop the clock\n",
        "end = time.time()\n",
        "print(\"Run took: \" + str(end - start) + ' seconds')"
      ],
      "metadata": {
        "id": "Y7nhEPdXDmN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}