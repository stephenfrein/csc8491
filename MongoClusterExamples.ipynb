{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4ujVXG4RTIVsJHofuO7Fe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenfrein/csc8491/blob/main/MongoClusterExamples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HvVnN1_Ad3Hq",
        "outputId": "b7b9261a-4d2c-40f8-bdd4-391d86d15812",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.1/669.1 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.6.1 pymongo-4.7.3\n"
          ]
        }
      ],
      "source": [
        "# install a Python library that interacts with MongoDB\n",
        "!pip install pymongo\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set up your credentials - same as your Oracle credentials\n",
        "username = ''\n",
        "password = ''"
      ],
      "metadata": {
        "id": "mL1rA7wIelJ3"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test your connection - if it fails, check username/password\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi\n",
        "uri = \"mongodb+srv://\"+username+\":\"+password+\"@cluster0.yrg2exm.mongodb.net\"\n",
        "# create a new client and connect to the server\n",
        "client = MongoClient(uri, server_api=ServerApi('1'))\n",
        "# send a ping to confirm a successful connection\n",
        "try:\n",
        "    client.admin.command('ping')\n",
        "    print(\"Pinged your deployment. You successfully connected to MongoDB!\")\n",
        "except Exception as e:\n",
        "    print(e)"
      ],
      "metadata": {
        "id": "dF1xxX37ehE9",
        "outputId": "5d568f9c-9c82-47f6-c8ff-35a8f6fae5c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pinged your deployment. You successfully connected to MongoDB!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OBSERVE THE PROPAGATION DELAY IN A CLUSTER\n",
        "\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import threading\n",
        "import time\n",
        "from pymongo import ReadPreference\n",
        "\n",
        "# transactions in a CSV file in an AWS S3 bucket\n",
        "transactions_url = 'https://csc8491.s3.amazonaws.com/mongo_transactions.csv'\n",
        "# name of collection\n",
        "trans_collection = 'transactions'\n",
        "\n",
        "# you have a database that matches your username\n",
        "db = client[username]\n",
        "collection = db[trans_collection]\n",
        "\n",
        "# get rid of collection if it already exists\n",
        "try:\n",
        "  collection.drop()\n",
        "except e:\n",
        "  print(e)\n",
        "\n",
        "# function to load our collection from the S3 file - we'll run this in a thread\n",
        "def load_collection(collection, filename):\n",
        "    data = pd.read_csv(filename, header=0)\n",
        "    collection.insert_many(data.to_dict('records'))\n",
        "\n",
        "# function to get the count in a collection - we'll read this for both the primary and a secondary\n",
        "def get_count(collection, type):\n",
        "  # we read it 20 times in a row to compare how loading progresses for the primary or the secondary\n",
        "  for i in range(1,21):\n",
        "    print('\\n' + type + ' ' + str(i) + ': ' + str(collection.count_documents({})) + ' ' + str(datetime.datetime.now()))\n",
        "\n",
        "# reference to the collection for loading\n",
        "trans_load = db.get_collection(trans_collection)\n",
        "# reference to the collection as it exists on the primary node - we will use for reading\n",
        "trans_primary = db.get_collection(trans_collection, read_preference=ReadPreference.PRIMARY)\n",
        "# reference to the collection as it exists on a secondary node - we will use for reading\n",
        "trans_secondary = db.get_collection(trans_collection, read_preference=ReadPreference.SECONDARY)\n",
        "\n",
        "# thread for loading data\n",
        "t_load_data = threading.Thread(target=load_collection, args=(trans_load,transactions_url,))\n",
        "# thread for reading from primary\n",
        "t_count_primary = threading.Thread(target=get_count, args=(trans_primary,'Primary',))\n",
        "# thread for reading froms secondary\n",
        "t_count_secondary = threading.Thread(target=get_count, args=(trans_secondary,'Secondary',))\n",
        "\n",
        "# start the clock\n",
        "start = time.time()\n",
        "\n",
        "# starting load thread\n",
        "t_load_data.start()\n",
        "# give load time to get moving\n",
        "time.sleep(15)\n",
        "# start reading from primary\n",
        "t_count_primary.start()\n",
        "# start reading from secondary\n",
        "t_count_secondary.start()\n",
        "\n",
        "# wait until threads are completely executed\n",
        "t_load_data.join()\n",
        "t_count_primary.join()\n",
        "t_count_secondary.join()\n",
        "\n",
        "# stop the clock\n",
        "end = time.time()\n",
        "print(\"Run took: \" + str(end - start) + ' seconds')\n",
        "\n",
        "# what are our final numbers once load is complete?\n",
        "print('Final Primary: ' + str(trans_primary.count_documents({})))\n",
        "print('Final Secondary: ' + str(trans_secondary.count_documents({})))\n"
      ],
      "metadata": {
        "id": "nNgVKZVTGxlE",
        "outputId": "c5f988d0-8804-4574-9126-bf6ef18ed9eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Secondary 1: 69536 2024-06-17 17:53:46.332463\n",
            "\n",
            "Secondary 2: 69536 2024-06-17 17:53:46.547600\n",
            "\n",
            "Secondary 3: 69536 2024-06-17 17:53:46.788059\n",
            "\n",
            "Secondary 4: 69536 2024-06-17 17:53:47.002561\n",
            "\n",
            "Secondary 5: 69536 2024-06-17 17:53:47.215122\n",
            "\n",
            "Secondary 6: 69536 2024-06-17 17:53:47.446126\n",
            "\n",
            "Secondary 7: 69536 2024-06-17 17:53:47.683865\n",
            "\n",
            "Secondary 8: 69536 2024-06-17 17:53:47.898946\n",
            "\n",
            "Secondary 9: 69536 2024-06-17 17:53:48.112116\n",
            "\n",
            "Secondary 10: 69536 2024-06-17 17:53:48.358785\n",
            "\n",
            "Secondary 11: 69536 2024-06-17 17:53:48.603022\n",
            "\n",
            "Secondary 12: 69536 2024-06-17 17:53:48.849076\n",
            "\n",
            "Secondary 13: 69536 2024-06-17 17:53:49.061923\n",
            "\n",
            "Secondary 14: 69536 2024-06-17 17:53:49.273749\n",
            "\n",
            "Secondary 15: 69536 2024-06-17 17:53:49.538568\n",
            "\n",
            "Secondary 16: 69536 2024-06-17 17:53:49.755037\n",
            "\n",
            "Secondary 17: 69536 2024-06-17 17:53:49.967534\n",
            "\n",
            "Secondary 18: 69536 2024-06-17 17:53:50.179251\n",
            "\n",
            "Secondary 19: 69536 2024-06-17 17:53:50.440857\n",
            "\n",
            "Secondary 20: 69536 2024-06-17 17:53:50.705804\n",
            "\n",
            "Primary 1: 91104 2024-06-17 17:53:55.282224\n",
            "\n",
            "Primary 2: 111776 2024-06-17 17:53:59.137097\n",
            "\n",
            "Primary 3: 114656 2024-06-17 17:54:00.610262\n",
            "\n",
            "Primary 4: 122080 2024-06-17 17:54:02.328950\n",
            "\n",
            "Primary 5: 136352 2024-06-17 17:54:04.247299\n",
            "\n",
            "Primary 6: 138464 2024-06-17 17:54:05.689303\n",
            "\n",
            "Primary 7: 151328 2024-06-17 17:54:07.607104\n",
            "\n",
            "Primary 8: 162016 2024-06-17 17:54:09.853531\n",
            "\n",
            "Primary 9: 172640 2024-06-17 17:54:11.975534\n",
            "\n",
            "Primary 10: 190048 2024-06-17 17:54:14.577907\n",
            "\n",
            "Primary 11: 204512 2024-06-17 17:54:16.831302\n",
            "\n",
            "Primary 12: 214432 2024-06-17 17:54:19.091796\n",
            "\n",
            "Primary 13: 225632 2024-06-17 17:54:21.691597\n",
            "\n",
            "Primary 14: 243168 2024-06-17 17:54:24.764042\n",
            "\n",
            "Primary 15: 260736 2024-06-17 17:54:27.972054\n",
            "\n",
            "Primary 16: 269536 2024-06-17 17:54:30.709134\n",
            "\n",
            "Primary 17: 269536 2024-06-17 17:54:33.502095\n",
            "\n",
            "Primary 18: 269536 2024-06-17 17:54:35.310564\n",
            "\n",
            "Primary 19: 289952 2024-06-17 17:54:40.531640\n",
            "\n",
            "Primary 20: 317664 2024-06-17 17:54:45.847206\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Exception in thread Thread-16 (load_collection):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 1016, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.10/threading.py\", line 953, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"<ipython-input-6-5834830b892e>\", line 27, in load_collection\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/_csot.py\", line 108, in csot_wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/collection.py\", line 742, in insert_many\n",
            "    blk.execute(write_concern, session, _Op.INSERT)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/bulk.py\", line 595, in execute\n",
            "    return self.execute_command(generator, write_concern, session, operation)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/bulk.py\", line 452, in execute_command\n",
            "    client._retryable_write(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\", line 1569, in _retryable_write\n",
            "    return self._retry_with_session(retryable, func, s, bulk, operation, operation_id)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\", line 1455, in _retry_with_session\n",
            "    return self._retry_internal(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/_csot.py\", line 108, in csot_wrapper\n",
            "    return func(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\", line 1501, in _retry_internal\n",
            "    ).run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\", line 2347, in run\n",
            "    return self._read() if self._is_read else self._write()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/mongo_client.py\", line 2464, in _write\n",
            "    return self._func(self._session, conn, self._retryable)  # type: ignore\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/bulk.py\", line 441, in retryable_bulk\n",
            "    self._execute_command(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/bulk.py\", line 386, in _execute_command\n",
            "    result, to_send = bwc.execute(cmd, ops, client)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/message.py\", line 960, in execute\n",
            "    result = self.write_command(cmd, request_id, msg, to_send, client)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/helpers.py\", line 342, in inner\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/message.py\", line 1118, in write_command\n",
            "    reply = self.conn.write_command(request_id, msg, self.codec)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/pool.py\", line 1078, in write_command\n",
            "    helpers._check_command_response(result, self.max_wire_version)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pymongo/helpers.py\", line 248, in _check_command_response\n",
            "    raise OperationFailure(errmsg, code, response, max_wire_version)\n",
            "pymongo.errors.OperationFailure: you are over your space quota, using 527 MB of 512 MB, full error: {'ok': 0, 'errmsg': 'you are over your space quota, using 527 MB of 512 MB', 'code': 8000, 'codeName': 'AtlasError'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run took: 340.94284987449646 seconds\n",
            "Final Primary: 1533065\n",
            "Final Secondary: 1533065\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OBSERVE THE PERFORMANCE IMPACTS OF DIFFERENT WRITE CONCERNS\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "from pymongo import WriteConcern\n",
        "\n",
        "# transactions in a CSV file in an AWS S3 bucket\n",
        "transactions_url = 'https://csc8491.s3.amazonaws.com/mongo_transactions.csv'\n",
        "# name of collection\n",
        "trans_collection = 'transactions'\n",
        "\n",
        "# you have a database that matches your username\n",
        "db = client[username]\n",
        "collection = db[trans_collection]\n",
        "\n",
        "# get rid of collection if it already exists\n",
        "try:\n",
        "  collection.drop()\n",
        "except e:\n",
        "  print(e)\n",
        "\n",
        "# function to load our collection from the S3 file\n",
        "# do it in a loop to better see performance impacts\n",
        "def load_collection(collection, filename):\n",
        "    df = pd.read_csv(filename, header=0)\n",
        "    df = df.iloc[:1000] # grab first thousand records\n",
        "    for index, row in df.iterrows():\n",
        "      collection.insert_one(row.to_dict())\n",
        "\n",
        "# reference to the collection for loading\n",
        "# manipulate write concern to affect speed\n",
        "\n",
        "# default gives majority - 2 nodes in this 3-node cluster (primary + 1 secondary)\n",
        "trans_load = db.get_collection(trans_collection)\n",
        "# setting write concern to 0 means no write acknowledgement needed - super fast\n",
        "# trans_load = db.get_collection(trans_collection, write_concern=WriteConcern(w=0))\n",
        "# setting write concern to 1 means just the primary has to acknowledge\n",
        "# trans_load = db.get_collection(trans_collection, write_concern=WriteConcern(w=1))\n",
        "\n",
        "# start the clock\n",
        "start = time.time()\n",
        "# load the data\n",
        "load_collection(trans_load, transactions_url)\n",
        "# stop the clock\n",
        "end = time.time()\n",
        "print(\"Run took: \" + str(end - start) + ' seconds')"
      ],
      "metadata": {
        "id": "Y7nhEPdXDmN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}