{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "authorship_tag": "ABX9TyO+VwlzvaBQIaITsBsKIm0x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stephenfrein/csc8491/blob/main/Homework4_Frein.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 1"
      ],
      "metadata": {
        "id": "QCgIi6ECv-oY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fuzzycars = read.csv2('https://csc8491.s3.amazonaws.com/car_data.csv', stringsAsFactors = TRUE)"
      ],
      "metadata": {
        "id": "hdOEsZFrwDmq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(12345678)\n",
        "sample = sample(1:nrow(fuzzycars), 0.8 * nrow(fuzzycars))\n",
        "cars.train = fuzzycars[sample, ]\n",
        "cars.test = fuzzycars[-sample, ]\n",
        "sprintf(\"Training rows: %s\", nrow(cars.train))\n",
        "sprintf(\"Testing rows: %s\", nrow(cars.test))"
      ],
      "metadata": {
        "id": "oy5DIo-EwPLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"tree\")"
      ],
      "metadata": {
        "id": "uIl8Z-GwxGMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(cars.train)"
      ],
      "metadata": {
        "id": "5efR7Z9FQt9c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "library(tree)\n",
        "cars.tree = tree(acceptability ~ ., cars.train)\n",
        "summary(cars.tree)"
      ],
      "metadata": {
        "id": "bTY-076pxgtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot(cars.tree)\n",
        "text(cars.tree, pretty=0)\n"
      ],
      "metadata": {
        "id": "1UoGYvXixqdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars.preds = predict(cars.tree, cars.test, type=\"class\")\n",
        "cars.actuals = cars.test$acceptability\n",
        "table(cars.preds, cars.actuals)"
      ],
      "metadata": {
        "id": "PFUfLatex6Cs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "cm = as.data.frame(table(cars.preds, cars.actuals))\n",
        "cm\n"
      ],
      "metadata": {
        "id": "_Oq284NF0dEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\")\n",
        "# number correctly predicted                       / total number\n",
        "sum(cm[cm$cars.preds==cm$cars.actuals, c('Freq')]) / nrow(cars.test)"
      ],
      "metadata": {
        "id": "9p14PrJS3fG9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision:\")\n",
        "# assume \"acceptable\" is positive class\n",
        "# number correctly predicted as acceptable                        /  number predicted as acceptable\n",
        "sum(cm[cm$cars.preds==\"acc\" & cm$cars.actuals==\"acc\", c('Freq')]) / sum(cm[cm$cars.preds==\"acc\",c('Freq')])"
      ],
      "metadata": {
        "id": "PqqbSZkq0qBr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recall:\")\n",
        "# assume \"acceptable\" is positive class\n",
        "# number correctly predicted as acceptable                        /  total acceptable\n",
        "sum(cm[cm$cars.preds==\"acc\" & cm$cars.actuals==\"acc\", c('Freq')]) / sum(cm[cm$cars.actuals==\"acc\",c('Freq')])"
      ],
      "metadata": {
        "id": "dtfurRtv4t3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy was higher in summary() function. This isn't surprising, since summary reports accuracy on the data the model was trained on."
      ],
      "metadata": {
        "id": "fVUPGnnW5ekQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_car = data.frame(purchase_price=as.factor(c(\"high\")), maint_cost=as.factor(c(\"high\")), num_doors=c(2), num_persons=c(4), trunk_size=as.factor(c(\"small\")), safety_rating=as.factor((\"high\")))\n",
        "new_car"
      ],
      "metadata": {
        "id": "NHg9Yea9Hh_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predict(cars.tree, new_car, type=\"class\")\n",
        "predict(cars.tree, new_car)"
      ],
      "metadata": {
        "id": "W8rls8kyJJhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "install.packages(\"randomForest\")\n",
        "library(randomForest)"
      ],
      "metadata": {
        "id": "8kViscMcUgJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars.rf = randomForest(acceptability~., data=cars.train, importance = TRUE)\n",
        "cars.rf"
      ],
      "metadata": {
        "id": "Y8bjDFwWUtgA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cars.preds.rf = predict(cars.rf, cars.test, type=\"class\")\n",
        "table(cars.preds.rf, cars.actuals)"
      ],
      "metadata": {
        "id": "EYRbzwD8VtpH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = as.data.frame(table(cars.preds.rf, cars.actuals))\n",
        "cm"
      ],
      "metadata": {
        "id": "AAol9FUBWRld"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy:\")\n",
        "# number correctly predicted                       / total number\n",
        "sum(cm[cm$cars.preds.rf==cm$cars.actuals, c('Freq')]) / nrow(cars.test)"
      ],
      "metadata": {
        "id": "JB8eKHDEuuRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision:\")\n",
        "# assume \"acceptable\" is positive class\n",
        "# number correctly predicted as acceptable                        /  number predicted as acceptable\n",
        "sum(cm[cm$cars.preds.rf==\"acc\" & cm$cars.actuals==\"acc\", c('Freq')]) / sum(cm[cm$cars.preds.rf==\"acc\",c('Freq')])"
      ],
      "metadata": {
        "id": "8HQfP7KVu3M9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recall:\")\n",
        "# assume \"acceptable\" is positive class\n",
        "# number correctly predicted as acceptable                        /  total acceptable\n",
        "sum(cm[cm$cars.preds.rf==\"acc\" & cm$cars.actuals==\"acc\", c('Freq')]) / sum(cm[cm$cars.actuals==\"acc\",c('Freq')])"
      ],
      "metadata": {
        "id": "TYvK-lGzvIz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importance(cars.rf)\n",
        "varImpPlot(cars.rf)\n"
      ],
      "metadata": {
        "id": "Ubflc1GAvVUN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 2"
      ],
      "metadata": {
        "id": "WkXCophbv-Qq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# H = laptop will fail\n",
        "# E - employee is from sales\n",
        "#P(H|E)        = P(E|H) * P(H) / P(E)\n",
        "posterior_prob = .15    * .05  / .08\n",
        "sprintf(\"Percent chance the laptop will fail: %s%%\", posterior_prob * 100)"
      ],
      "metadata": {
        "id": "MorDCg5_vowg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Part 3"
      ],
      "metadata": {
        "id": "xI6-cqvxnACY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3i1ftiqgUEOP"
      },
      "outputs": [],
      "source": [
        "twts = read.csv(\"https://csc8491.s3.amazonaws.com/nova_tweets.csv\")\n",
        "str(twts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "twts$tod = as.factor(ifelse((twts$tod>=20 | twts$tod < 6),\"night\",\"day\"))\n",
        "str(twts)\n",
        "table(twts$tod)\n",
        "prop.table(table(twts$tod))"
      ],
      "metadata": {
        "id": "DC0J7KHPU60E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "head(twts)\n"
      ],
      "metadata": {
        "id": "2NEM4W6wVqYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build a corpus (body of docs) using the text mining (tm) package\n",
        "install.packages(\"tm\")\n",
        "install.packages(\"SnowballC\")\n",
        "library(tm)"
      ],
      "metadata": {
        "id": "Vk___b0IXuEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# VCorpus is an in-memory (volatile) corpus â€“ simplest choice here\n",
        "twt_corpus <- VCorpus(VectorSource(twts$tweet_txt))\n",
        "twt_corpus_clean <- tm_map(twt_corpus, content_transformer(tolower))\n",
        "# remove numbers\n",
        "twt_corpus_clean <- tm_map(twt_corpus_clean, removeNumbers)\n",
        "# remove punctuation\n",
        "twt_corpus_clean <- tm_map(twt_corpus_clean, removePunctuation)\n",
        "# remove stop words\n",
        "twt_corpus_clean <- tm_map(twt_corpus_clean, removeWords, stopwords())\n",
        "# now stem our actual corpus\n",
        "twt_corpus_clean <- tm_map(twt_corpus_clean, stemDocument)\n",
        "# eliminate unneeded whitespace\n",
        "twt_corpus_clean <- tm_map(twt_corpus_clean, stripWhitespace)\n",
        "# examine the final clean corpus\n",
        "lapply(twt_corpus[1:3], as.character)\n",
        "lapply(twt_corpus_clean[1:3], as.character)\n"
      ],
      "metadata": {
        "id": "SY-RofuBX7e3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a document-term sparse matrix\n",
        "twt_dtm <- DocumentTermMatrix(twt_corpus_clean)\n",
        "# creating training and test datasets\n",
        "train_pct <- .8\n",
        "set.seed(123)\n",
        "train = sample(1:nrow(twt_dtm), train_pct * nrow(twt_dtm))\n",
        "twt_dtm_train <- twt_dtm[train, ]\n",
        "twt_dtm_test  <- twt_dtm[-train, ]\n"
      ],
      "metadata": {
        "id": "OfCiErdCZ1Iz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# also save the labels\n",
        "twt_train_labels <- twts[train, ]$tod\n",
        "twt_test_labels  <- twts[-train, ]$tod\n",
        "# check that the proportion of spam is similar\n",
        "prop.table(table(twt_train_labels))\n",
        "prop.table(table(twt_test_labels))"
      ],
      "metadata": {
        "id": "G4XGCmgvaSiV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# save frequently-appearing terms to a character vector\n",
        "twt_freq_words <- findFreqTerms(twt_dtm_train, 5)\n",
        "str(twt_freq_words)"
      ],
      "metadata": {
        "id": "N0fpjR73bhOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create DTMs with only the frequent terms\n",
        "twt_dtm_freq_train <- twt_dtm_train[ , twt_freq_words]\n",
        "twt_dtm_freq_test <- twt_dtm_test[ , twt_freq_words]"
      ],
      "metadata": {
        "id": "egFtmjtgbqBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# convert counts to presence indicator - # times not important\n",
        "convert_counts <- function(x) {\n",
        "  return(ifelse(x > 0, \"Yes\", \"No\"))\n",
        "}\n",
        "# apply() convert_counts() to columns of train/test data\n",
        "twt_train <- apply(twt_dtm_freq_train, MARGIN = 2, convert_counts)\n",
        "twt_test  <- apply(twt_dtm_freq_test, MARGIN = 2, convert_counts)"
      ],
      "metadata": {
        "id": "HGhB-K9Kb2wJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# install naive bayes packages\n",
        "install.packages(\"e1071\")\n",
        "library(e1071)"
      ],
      "metadata": {
        "id": "kzAftnxlcF7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twt_classifier <- naiveBayes(twt_train, twt_train_labels)\n",
        "# evaluating model performance ----\n",
        "twt_test_pred <- predict(twt_classifier, twt_test)\n",
        "table(twt_test_pred, twt_test_labels)"
      ],
      "metadata": {
        "id": "6V8GdkXIcS3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = as.data.frame(table(twt_test_pred, twt_test_labels))\n",
        "typeof(cm)\n",
        "cm"
      ],
      "metadata": {
        "id": "SU2N2mSvkIQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Precision:\")\n",
        "# assume \"day\" is positive class\n",
        "# number correctly predicted as day                                     /  number predicted as day\n",
        "sum(cm[cm$twt_test_pred==\"day\" & cm$twt_test_labels==\"day\", c('Freq')]) / sum(cm[cm$twt_test_pred==\"day\",c('Freq')])"
      ],
      "metadata": {
        "id": "Jg5Jk6dLkn_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Recall:\")\n",
        "# assume \"day\" is positive class\n",
        "# number correctly predicted as day                                     /  total number of days\n",
        "sum(cm[cm$twt_test_pred==\"day\" & cm$twt_test_labels==\"day\", c('Freq')]) / sum(cm[cm$twt_test_labels==\"day\",c('Freq')])"
      ],
      "metadata": {
        "id": "_ja6wPjTmR_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nrow(twt_test)"
      ],
      "metadata": {
        "id": "DcOIa8I2aIW1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}